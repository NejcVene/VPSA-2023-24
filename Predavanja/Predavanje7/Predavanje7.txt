Anatomija GPE:
    Dekodiranje ukaza -> podati operande va vhod tretje stopnje (EX).
                         Pomeni, prebrati iz registrov in poslati na vhod EX.
    Operande prebere iz registrov in rezultat shrani v registre.

    Lahko imamo več ALE (EX) in vsi ti bodo obdelali del podatkov npr. en po 8, drugi po 4 ...
    Potem bi vsak ALE 16-krat izvedel zanko. Takemu procesroju rečemo "računska enota oz. compute unit oz. streaming multiprorcessor".
    Eni ALE pa rečemo temu "procesing element oz. streaming processor/core".

    Lahko to naredimo še hitreje, da vsak ALE izvede samo eno iteracijo zanke. Potem rabimo 128 ALE enot
    in zanke sploh ne potrebujemo več - vsak sešteje tista dva elementa, ki se nahajata na istem indexu
    kot je index te ALE. Temu skupaj pa lahko rečemo GPU.
    Ker je veliko jeder (procesnih elementov), takšnim arhitekturam rečemo "mnogo jederna arhitekutra oz. many core".

Primer: Kepler K40
    Ima 192 CU, torej lahko naredi 192 iteracij ene zanke naenkrat.
    Poleg teh 192 jeder, ima tudi 64 double precision floating point PE.
    32 load/store enot.
    64 KB skupnega pomnilnika (da si lahko teh 192 procesnih elementov deli podatke). Deluje lahko
    tudi kot L1 cache (predpomnilnik).
    64 K 32 bitnih registrov. Zakaj jih sploh toliko rabimo?
    Dispatch unit -> lahko izstavi naenkrat 8 različnih ukazov.
    Warp scheduler ->
    Tex -> operacije za strukture (tega se nas ne tiče).

    Celotna Kepler K40 GPU ima 15 compute unitov (15 * 192 = 2880 procesnih elementov).
    Lahko izvede 2880 aritmetičnih operacij naenkrat.

GPU, ki ga uporabljamo mi je Volta:
    64 int PE
    Tensor core -> posebna vrsta ALE, ki dela množenje vektorjev.
    
    Ima 6 particij. Vsaka particija ima 14 CU/particija.
    Ima 6 * 14 * 64 PE = 5376 (toliko operacij lahko naenkrat izvede).

=================================================================================

Programski vidik GPE:
    1. Izvajalni model:
       Pove, kako se bodo programi izvajali. Kot veliko število niti.
       Funkcijo, ko jo zaženemo na GPU se reče "ščepec oz. kernel".
       Vsak ščepec izvaja N niti (N >> 1000). Te niti so grupirane v skupine, ki
       jim pravimo bloki. Niti iz istega bloka se izvajajo na eni sami računski enoti oz. CU.
       Niti znotraj bloka, ker se izvajajo na isti računski enkoti (CU), lahko komunicirajo
       (izmenjujejo podatke preko skupnega pomnilnika) in se lahko sinhronizirajo.
       Niti znotraj istega bloka se delijo/grupirajo v skupke, po 32 niti -> tej 32 niti
       imajo vedno zaporedne indekse (tem nitim rečemo snop oz. warp).
       Snop niti predstavlja minimalno število niti, ki se naenkrat izvede (minimalna granulacija).
       Naenkrat izvede -> vse niti v snopu izvedejo isti ukaz.
       CU ima 4 razvrščevalnike snopov, torej CU lahko naenkrat izvede 4 * 32 niti oz. ALE ukazov.

       Bloki in snopi se razvrščajo popolnoma nedovisno.
       Možno je, da je število blokov > število CU (to je zaželjeno, da se naredi, ker
       če nek CU v bloku, ki ga izvaja ne najde nobenega snopa, ki je pripravljen na izvajanje
       bo vzel nov blok v izvajanje. Zato je dobro, da ima CU več blokov na izbiro).
    2. Pomnilniška hierarhija:
       
Velikost mreže: M (število blokov)
Velikost bloka: B (število niti v bloku)

Niti pri GPU nimajo globalnega indeksa, vendar niti imajo indeks če znotraj bloka:
    blok 0: nit 0 v blok 0
    blok 1: nit 0 v blok 1
    blok n: nit 0 v blok n

Kateri element obdeluje nit 2 v bloku 2?
    indeks bloka * velikost bloka + indeks niti v bloku

Primer: seštevanje vektorjev
    Koliko niti bomo uporabili? Odvisno od velikosti problema:
        npr. vektor je dolg T - 1 elementov. Blok je velikost B (to ni bajt!).
             Blokov je M. M = T / B (število blokov) <- mreža niti oz. blokov (grid).
             Cilj: da je M > števila CU.
                   da je B > k * 32, k >= 4 (zato, da bo več snopov v bloku).
    Naivno seštevanje vektorjev:
        Nit i naj sešteje le i-to istoležna elementa.


cudaGetDeviceCount(int *) vrne koliko naprav podpira CUDA
cudaGetDeviceProperties(struct *cudaDeviceProp, int) zapiše v strukturo lastnosti naprave, ki podpira CUDA
cudaDeviceGetAttribute() vrne izvajalni mode

Kako prevedit program:
    1. V direktorij programa
    2. module load CUDA
    3. nvcc -o program.cu program
    4. srun --partition=gpu --ntasks=1 --gpus=1 program
